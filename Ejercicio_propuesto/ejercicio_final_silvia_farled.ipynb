{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd26277b",
   "metadata": {},
   "source": [
    "#### FASE 0: CONFIGURACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Imputación de nulos usando métodos avanzados estadísticos\n",
    "# -----------------------------------------------------------------------\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "# Librerías de visualización\n",
    "# -----------------------------------------------------------------------\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Evaluar linealidad de las relaciones entre las variables\n",
    "# ------------------------------------------------------------------------------\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro, poisson, chisquare, expon, kstest\n",
    "from scipy.stats import levene, bartlett, shapiro\n",
    "\n",
    "# Gestión de los warnings\n",
    "# -----------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Para evitar errores en el uso de palette en seaborn\n",
    "\n",
    "\n",
    "# ver todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "# ver todas las filas\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1908c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función EDA\n",
    "\n",
    "def basic_eda(df):\n",
    "\n",
    "    print('🌷Ejemplo de datos del DF:')\n",
    "    display(df.head(3))\n",
    "    display(df.tail(3))\n",
    "    display(df.sample(3))\n",
    "    print('________________________________________________________________________________________________________')\n",
    "\n",
    "    print('🌻Número de Filas:')\n",
    "    display(df.shape[0])\n",
    "    print('________________________________________________________________________________________________________')\n",
    "\n",
    "    print('🌱Número de Columnas:')\n",
    "    display(df.shape[1])\n",
    "    print('________________________________________________________________________________________________________')\n",
    "\n",
    "    print('🌼Información de la tabla:')\n",
    "    display(df.info())\n",
    "    print('________________________________________________________________________________________________________')\n",
    "\n",
    "    print('🌑Nombre de las columnas:')\n",
    "    display(df.columns)\n",
    "    print('________________________________________________________________________________________________________')\n",
    "\n",
    "    print('🍄Descripción de los datos numéricos:')\n",
    "    display(df.describe().T)\n",
    "    print('________________________________________________________________________________________________________')\n",
    "\n",
    "    print('🌋Descripción de los datos no-numéricos:')\n",
    "    try:\n",
    "        display(df.describe(include='object').T)\n",
    "    except:\n",
    "        pass\n",
    "    print('________________________________________________________________________________________________________')\n",
    "\n",
    "    print('🍂Saber si hay datos únicos:')\n",
    "    display(df.nunique())\n",
    "    print('________________________________________________________________________________________________________')\n",
    "\n",
    "    print('🐖Que datos son nulos por columnas:')\n",
    "    display(df.isnull().sum())\n",
    "    print('________________________________________________________________________________________________________')\n",
    "\n",
    "    print('🐲Filas duplicadas:')\n",
    "    total_duplicados = df.duplicated().sum()\n",
    "    if total_duplicados > 0:\n",
    "        print(f'cantidad de duplicados: {total_duplicados}')\n",
    "        print('Primeros duplicados')\n",
    "        display(df[df.duplicated()].head(3))\n",
    "    else:\n",
    "        print('No hay duplicados')\n",
    "    print('________________________________________________________________________________________________________')\n",
    "\n",
    "    print('🪹 Columnas constantes (solo 1 valor único):')\n",
    "    constantes = df.columns[df.nunique() <= 1]\n",
    "    if len(constantes) > 0:\n",
    "        print(f'{len(constantes)} columnas con 1 valor único:')\n",
    "        display(constantes)\n",
    "    else:\n",
    "        print('No hay columnas constantes')\n",
    "    print('________________________________________________________________________________________________________')\n",
    "    \n",
    "    print('🚀 Valores únicos en columnas categóricas:')\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        print(f'🔸 {col}')\n",
    "        print('-----------------------------')\n",
    "        print(df[col].unique())\n",
    "        print('________________________________________________________________________________________________________')\n",
    "\n",
    "    print('🧬 Tipos de datos por columna:')\n",
    "    display(df.dtypes.value_counts())\n",
    "    print('________________________________________________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e97d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función unión de tablas con el método \"right\"\n",
    "\n",
    "def to_union(df1,df2):\n",
    "    df_new = df1.merge(df2, how='right')\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para localizar y eliminar los registros duplicados\n",
    "\n",
    "def duplicates(df):\n",
    "    if df.duplicated().sum() > 0:\n",
    "        df= df.drop_duplicates()\n",
    "        return df\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b3bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cambiar el tipo de dato de una columna según necesidad\n",
    "\n",
    "def change_data(df, column, type):\n",
    "    try:\n",
    "        if type == \"int\":\n",
    "            df[column] = df[column].astype(int)\n",
    "        elif type == \"object\":\n",
    "            df[column] = df[column].astype(str)\n",
    "        elif type == \"datetime\":\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "        elif type == \"float\":\n",
    "            df[column] = df[column].astype(float)\n",
    "        else:\n",
    "            print(\"Solo se acepta: int, object, datetime o float\")\n",
    "    except:\n",
    "        print(\"Hay nulos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aaa72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para concatenar las fechas en una sola columna y eliminar las originales\n",
    "\n",
    "def date_union (df, year_column, month_column, date_column): \n",
    "    localizacion = df.columns.get_loc(year_column)\n",
    "    df.insert(localizacion, date_column, None)\n",
    "    df[date_column] = df[year_column].astype(str) + \"-\" + df[month_column].astype(str).str.zfill(2) + \"-01\"\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    df[date_column] = df[date_column].dt.date\n",
    "    df.drop([year_column, month_column], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para realizar una prueba de hipótesis con múltiples grupos\n",
    "\n",
    "def multigroup_hypothesis_test(*args):\n",
    "\n",
    "    \"\"\"\n",
    "    Realiza una prueba de hipótesis para comparar grupos.\n",
    "    1. Primero verifica si los datos son normales usando el test de Shapiro-Wilk o Kolmogorov-Smirnov.\n",
    "    2. Si los datos son normales, usa Bartlett para probar igualdad de varianzas. Si no son normales, usa Levene.\n",
    "    3. Si las varianzas son iguales, usa el ANOVA; si no, usa la versión de Kruskal-Wallis.\n",
    "\n",
    "    Parámetros:\n",
    "    *args: listas o arrays con los datos de cada grupo. Espera VARIOS grupos a comparar\n",
    "\n",
    "    Retorna:\n",
    "    dict con resultados del test de normalidad, varianza e hipótesis.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if len(args) < 2:\n",
    "        raise ValueError(\"Se necesitan al menos dos conjuntos de datos para realizar la prueba.\")\n",
    "\n",
    "    # Test de normalidad por grupo\n",
    "    normality = []\n",
    "    for group in args:\n",
    "        if len(group) > 50:\n",
    "            p_value_norm = stats.kstest(group, 'norm').pvalue\n",
    "        else:\n",
    "            p_value_norm = stats.shapiro(group).pvalue\n",
    "        normality.append(p_value_norm > 0.05)\n",
    "\n",
    "    normal_data = all(normality)\n",
    "\n",
    "    # Test de igualdad de varianzas para todos los grupos juntos\n",
    "    if normal_data:\n",
    "        p_variance_value = stats.bartlett(*args).pvalue\n",
    "    else:\n",
    "        p_variance_value = stats.levene(*args, center=\"median\").pvalue\n",
    "\n",
    "    equal_variances = p_variance_value > 0.05\n",
    "\n",
    "    # Test final según normalidad y varianzas\n",
    "    if normal_data and equal_variances:\n",
    "        t_stat, p_value = stats.f_oneway(*args)\n",
    "        test_used = \"ANOVA\"\n",
    "    else:\n",
    "        t_stat, p_value = stats.kruskal(*args)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "\n",
    "    alfa = 0.05\n",
    "\n",
    "    result = {\n",
    "        \"Test de Normalidad\": normality,\n",
    "        \"Datos Normales\": normal_data,\n",
    "        \"p-valor Varianza\": p_variance_value,\n",
    "        \"Varianzas Iguales\": equal_variances,\n",
    "        \"Test Usado\": test_used,\n",
    "        \"Estadístico\": t_stat,\n",
    "        \"p-valor\": p_value,\n",
    "        \"Conclusión\": \"Rechazamos H0. Hay diferencias significativas entre grupos\" if p_value < alfa else \"No se rechaza H0. No hay diferencias significativas entre grupos\"\n",
    "    }\n",
    "\n",
    "    print(\"\\n📊 **Resultados de la Prueba de Hipótesis Multigrupos** 📊\")\n",
    "    print(f\"✅ Normalidad en todos los grupos: {'Sí' if normal_data else 'No'}\")\n",
    "    print(f\"   - Normalidad por grupo: {normality}\")\n",
    "    print(f\"✅ Varianzas: {'Iguales' if equal_variances else 'Desiguales'} (p = {p_variance_value:.4f})\")\n",
    "    print(f\"✅ Test aplicado: {test_used}\")\n",
    "    print(f\"📉 Estadístico: {t_stat:.4f}, p-valor: {p_value:.4f}\")\n",
    "    print(f\"🔍 Conclusión: {result['Conclusión']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos paleta de color para los gráficos \n",
    "\n",
    "pastel_colors = [\n",
    "    \"#A8DADC\",  # Verde azulado pastel (frío)\n",
    "    \"#FFE5B4\",  # Amarillo pastel (cálido)\n",
    "    \"#F1C0E8\",  # Lila suave (frío)\n",
    "    \"#FFD6D6\",  # Rosa melocotón muy suave (cálido)\n",
    "    \"#B5EAEA\",  # Turquesa pastel (frío)\n",
    "    \"#FFCBC1\",  # Salmón pastel (cálido)\n",
    "    \"#C1E1C1\",  # Verde menta claro (frío)\n",
    "    \"#FFE3E3\",  # Rosa claro (cálido)\n",
    "    \"#D4A5A5\",  # Marrón claro pastel (cálido)\n",
    "    \"#C6D8D3\",  # Verde grisáceo pastel (frío)\n",
    "    \"#F7E6C4\",  # Beige claro (cálido)\n",
    "    \"#B9AEDC\",  # Lavanda pastel (frío)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db91f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos valores para el formato de las tablas por defecto:\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'Comic Sans MS',\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'figure.facecolor' : 'lightgray',\n",
    "    'axes.facecolor': 'darkgray'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f8e07",
   "metadata": {},
   "source": [
    "#### FASE 1: EXPLORACIÓN Y LIMPIEZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa66ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el archivo 1\n",
    "\n",
    "df_fligh = pd.read_csv(\"Customer Flight Activity.csv\")\n",
    "df_fligh.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c8cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el archivo 2\n",
    "\n",
    "df_loyalty=pd.read_csv(\"Customer Loyalty History.csv\")\n",
    "df_loyalty.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función de EDA al archivo 1 para entender los datos\n",
    "\n",
    "basic_eda(df_fligh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función de EDA al archivo 2 para entender los datos\n",
    "\n",
    "basic_eda(df_loyalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tras comprobar que hay filas duplicadas en el archivo 1 usamos la función para eliminar duplicados\n",
    "\n",
    "df_fligh = duplicates(df_fligh)\n",
    "\n",
    "# Comprobamos también que la información del archivo 1 continene los vuelos reservados de los clientes. Si la columna de vuelos totales es 0 no aporta valor. Eliminamos las filas cuya columna es 0:\n",
    "\n",
    "df_fligh = df_fligh[df_fligh[\"Total Flights\"] != 0]\n",
    "\n",
    "# Unimos las dos tablas en una sola por el método right teniendo en cuenta que el archivo 2 tiene solo un registro por cliente y el archivo 1 tiene varios registros por cliente_\n",
    "\n",
    "df = to_union(df_loyalty, df_fligh)\n",
    "\n",
    "# Practicamos un nuevo análisis EDA sobre el archivo unificado: \n",
    "\n",
    "basic_eda(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f441d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos histogramas para valorar las columnas numéricas\n",
    "\n",
    "df.select_dtypes(include=[np.number]).hist(figsize=(16,12), bins=30, color = \"black\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que la columna Salary tiene valores negativos. Utilizamos .abs() para sacar el valor absoluto:\n",
    "\n",
    "df[\"Salary\"] = df[\"Salary\"].abs()\n",
    "\n",
    "# También tiene valores nulos. Elegimos el método KNN para la imputación y facilitamos otras columnas numéricas en las que apoyar la imputación: \n",
    "\n",
    "columns_to_imput = [\"Salary\", \"CLV\", \"Distance\", \"Points Accumulated\"]\n",
    "imputer_knn = KNNImputer(n_neighbors=5)\n",
    "df[columns_to_imput] = imputer_knn.fit_transform(df[columns_to_imput])\n",
    "\n",
    "# Completamos los nulos de las columnas de mes y año de cancelación a fechas absurdas en el futuro: \n",
    "\n",
    "df[\"Cancellation Year\"] = df[\"Cancellation Year\"].fillna(2262)\n",
    "df[\"Cancellation Month\"] = df[\"Cancellation Month\"].fillna(1)\n",
    "\n",
    "# Una vez gestionado los nulos, cambiamos el tipo de dato de estas columnas de float a int: \n",
    "\n",
    "columns_int = [\"Points Accumulated\", \"Salary\", \"Cancellation Year\", \"Cancellation Month\"]\n",
    "\n",
    "for column in columns_int: \n",
    "    change_data(df, column, \"int\")\n",
    "    print(f\"Cambiada la columna {column}\")\n",
    "\n",
    "# Concatenamos las fechas en una sola columna juntando el año, el mes y el día 1. Lo convertimos a datatime y eliminamos las columnas de año y mes iniciales con la función date_union: \n",
    "\n",
    "date_union(df, \"Enrollment Year\", \"Enrollment Month\", \"Enrollment Date\")\n",
    "date_union(df, \"Cancellation Year\", \"Cancellation Month\", \"Cancellation Date\")\n",
    "date_union(df, \"Year\", \"Month\", \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76506a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c96d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos en un nuevo csv los datos limpios para empezar con los ejercicios. \n",
    "\n",
    "df.to_csv(\"Customer_union.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091728c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Customer_union.csv\", index_col = 0)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e34a8",
   "metadata": {},
   "source": [
    "#### FASE 2: VISUALIZACIÓN  \n",
    "  \n",
    "- 1. ¿Cómo se distribuye la cantidad de vuelos reservados por mes durante el año?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2370fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para ejercicio 1\n",
    "\n",
    "df_booking = df.groupby(\"Date\")[\"Flights Booked\"].sum()\n",
    "df_booking.index = pd.to_datetime(df_booking.index)\n",
    "formatted_dates = df_booking.index.strftime(\"%B %Y\")  # Da formato a la columna para mostrar mes en letra\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x=formatted_dates, height=df_booking.values, color=pastel_colors, edgecolor='black')\n",
    "\n",
    "plt.xlabel('Meses')\n",
    "plt.ylabel('Vuelos Reservados')\n",
    "plt.title('Vuelos Reservados por Mes', fontsize=22)\n",
    "plt.xticks(rotation=45)\n",
    "ticks_y = np.arange(0, 110000, 10000)\n",
    "plt.yticks(ticks_y)\n",
    "plt.grid(True, axis='y', color='#eeeeee')\n",
    "plt.gca().spines[['right', \"top\"]].set_visible(False) # quitamos la línea de arriba y de la derecha\n",
    "plt.axvline(x=12 - 0.5, color='gray', linestyle='--', linewidth=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f93c3",
   "metadata": {},
   "source": [
    "Respuesta: tras poder comprobar la información por mes de dos años consecutivos vemos que el patrón se repite, siendo el mes con más movimiento el de julio pero seguido de cerca por los meses de junio, agosto y diciembre. Podemos relacionar estos picos con las vacaciones estivales y Navidad. Por contra, los meses con menos movimiento son enero y febrero que coincide con que no hay fiestas reseñables en estos meses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e44e08b",
   "metadata": {},
   "source": [
    "- 2. ¿Existe una relación entre la distancia de los vuelos y los puntos acumulados por los cliente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6315e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para ejercicio 2\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (20, 5))\n",
    "\n",
    "sns.regplot(x = \"Distance\", \n",
    "            y = \"Points Accumulated\", \n",
    "            data = df, \n",
    "            marker = \"d\", \n",
    "            line_kws = {\"color\": \"black\", \"linewidth\": 1}, # cambiamos el color y el grosor de la linea de tendencia\n",
    "            scatter_kws = {\"color\": \"crimson\", \"s\": 2}, # cambiamos el color y el tamaño de los puntos del scaterplot\n",
    "            ax = axes[0])\n",
    "axes[0].set_xlabel(\"Distancia\")\n",
    "axes[0].set_ylabel(\"Puntos Acumulados\")\n",
    "axes[0].set_title(\"Relación distancia recorrida y puntos acumulados\")\n",
    "axes[0].spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "df_corr = df[[\"Distance\", \"Points Accumulated\"]].corr( method = \"spearman\").round(2)\n",
    "df_corr.index = ['Distancia', 'Puntos']\n",
    "df_corr.columns = ['Distancia', 'Puntos']\n",
    "sns.heatmap(df_corr, \n",
    "            cmap='coolwarm', \n",
    "            annot=True, \n",
    "            fmt='.2f', \n",
    "            linewidths=0.5, \n",
    "            vmin=-1, \n",
    "            vmax=1, \n",
    "            ax = axes[1])\n",
    "axes[1].set_title(\"Matriz de Correlación de distancia recorrida y puntos acumulados\", fontsize=14)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39000e04",
   "metadata": {},
   "source": [
    "Respuesta: definitivamente sí, están estrechamente relacioneados. A más distancia recorrida en vuelo más puntos acumulan los clientes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b62c26",
   "metadata": {},
   "source": [
    "- 3. ¿Cuál es la distribución de los clientes por provincia o estado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f492c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para ejercicio 3\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "sns.countplot(data=df, \n",
    "              x=\"Province\", \n",
    "              order=df[\"Province\"].value_counts().index, \n",
    "              palette=pastel_colors, \n",
    "              edgecolor='black', \n",
    "              width=0.6)\n",
    "plt.title('Distribución de clientes por provincia')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Provincias')\n",
    "plt.ylabel('Número de clientes')\n",
    "plt.grid(True, axis='y', color='#eeeeee')\n",
    "plt.gca().spines[['right', \"top\"]].set_visible(False) # quitamos la línea de arriba y de la derecha\n",
    "plt.show()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a91307",
   "metadata": {},
   "source": [
    "Respuesta: Esta es la distribución, siendo con diferencia Ontario, British Columbia y Quebec las que acumulan la mayor parte de los clientes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c504b",
   "metadata": {},
   "source": [
    "- 4. ¿Cómo se compara el salario promedio entre los diferentes niveles educativos de los clientes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1bfb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para ejercicio 4\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "df_salary = df.groupby(\"Education\")[\"Salary\"].mean()\n",
    "order_education = ['High School or Below', 'College', 'Bachelor', 'Master', 'Doctor']\n",
    "df_salary = df_salary.reindex(order_education)\n",
    "df_salary.index = ['Secundaria', 'Técnica', 'Grado', 'Máster', 'Doctorado']\n",
    "\n",
    "df_salary.plot(kind='bar', color = pastel_colors, edgecolor='black', width=0.4)\n",
    "plt.title('Salario promedio por nivel de estudios')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Nivel de educación')\n",
    "plt.ylabel('Salario promedio')\n",
    "plt.grid(True, axis='y', color='#eeeeee')\n",
    "plt.gca().spines[['right', \"top\"]].set_visible(False) # quitamos la línea de arriba y de la derecha\n",
    "plt.show()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb466b",
   "metadata": {},
   "source": [
    "Respuesta: el salario aumenta en relación al nivel de estudios con la única excepción de que los técnicos cobran de media ligeramente más que las personas con grado universitario. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9d104",
   "metadata": {},
   "source": [
    "- 5. ¿Cuál es la proporción de clientes con diferentes tipos de tarjetas de fidelidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para ejercicio 5\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "\n",
    "df_fidelity = df[\"Loyalty Card\"].value_counts()\n",
    "plt.pie(df_fidelity.values, \n",
    "        labels= df_fidelity.index,\n",
    "        data = df, \n",
    "        autopct=  '%1.1f%%', \n",
    "        colors = pastel_colors, \n",
    "        textprops={'fontsize': 10}, \n",
    "        startangle=90, \n",
    "        wedgeprops={'edgecolor': 'black'} );\n",
    "plt.title('Proporción clientes por tarjeta de fidelidad',fontsize=18, fontname='Comic Sans MS')\n",
    "plt.axis('equal')  # Para que el círculo sea perfecto\n",
    "plt.show()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca2b1f",
   "metadata": {},
   "source": [
    "Respuesta: nada que añadir a lo reflejado en el gráfico:  \n",
    "  \n",
    "Star: 45.6%  \n",
    "Aurora: 20.6%  \n",
    "Nova: 33.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb9f657",
   "metadata": {},
   "source": [
    "- 6. ¿Cómo se distribuyen los clientes según su estado civil y género?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para ejercicio 6\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "new_names = [\"Casado\", \"Soltero\", \"Divorciado\"]\n",
    "sns.countplot(x = \"Marital Status\", \n",
    "              data = df,\n",
    "              palette = pastel_colors,\n",
    "              width=0.4, \n",
    "              hue = \"Gender\", \n",
    "              edgecolor='black')\n",
    "plt.xlabel(\"Estado civil\")\n",
    "plt.ylabel(\"Nº clientes\")\n",
    "plt.title('Distribución de clientes por género y estado civil')\n",
    "plt.xticks(ticks=range(len(new_names)), labels=new_names, rotation=0)\n",
    "plt.grid(True, axis='y', color='#eeeeee')\n",
    "plt.legend(title=\"Género\", labels=[\"Mujeres\", \"Hombres\"])\n",
    "plt.gca().spines[['right', \"top\"]].set_visible(False) # quitamos la línea de arriba y de la derecha\n",
    "plt.show()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda0e55",
   "metadata": {},
   "source": [
    "Respuesta: no hay diferencias reseñables entre género pero sí entre estado civil. Son lso casados los que más reservan seguidos de los solteros y en último caso los divorciados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63726f56",
   "metadata": {},
   "source": [
    "#### BONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58eb84",
   "metadata": {},
   "source": [
    "- Preparación de Datos: Filtra el conjunto de datos para incluir únicamente las columnas relevantes.   \n",
    "\n",
    "- Análisis Descriptivo: Agrupa los datos por nivel educativo y calcula estadísticas descriptivas básicas (como el promedio, la desviación estándar) del número de vuelos eservados para cada grupo.  \n",
    "  \n",
    "- Prueba Estadística: Realiza una prueba de hipótesis para determinar si existe una diferencia significativa en el número de vuelos reservados entre los diferentes niveles educativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbb317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Preparación de datos: Generamos un nuevo df con las columnas indicadas: \n",
    "\n",
    "df_bon = df[[\"Flights Booked\", \"Education\"]]\n",
    "\n",
    "#  Análisis descriptivo: Agrupamos para visualizar las variables por nivel de educación: \n",
    "\n",
    "df_bonus = df_bon.groupby(\"Education\")[\"Flights Booked\"].describe().T\n",
    "display(df_bonus)\n",
    "\n",
    "# Generamos una variable por cada nivel de educación y mostramos sólo la columna de vuelos reservados: \n",
    "\n",
    "bachelor_group = df_bon[df_bon[\"Education\"] == \"Bachelor\"][\"Flights Booked\"]\n",
    "college_group = df_bon[df_bon[\"Education\"] == \"College\"][\"Flights Booked\"]\n",
    "doctor_group = df_bon[df_bon[\"Education\"] == \"Doctor\"][\"Flights Booked\"]\n",
    "secondary_group = df_bon[df_bon[\"Education\"] == \"High School or Below\"][\"Flights Booked\"]\n",
    "master_group = df_bon[df_bon[\"Education\"] == \"Master\"][\"Flights Booked\"]\n",
    "\n",
    "# Prueba estadística: Activamos la función de la prueba de hipótesis adaptada para gestionar con varios grupos:\n",
    "\n",
    "multigroup_hypothesis_test(bachelor_group, college_group, doctor_group, secondary_group, master_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002339e",
   "metadata": {},
   "source": [
    "Respuesta : los niveles educativos analizados no muestran diferencias significativas en la cantidad promedio de vuelos reservados, según los datos y la prueba no paramétrica aplicada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
